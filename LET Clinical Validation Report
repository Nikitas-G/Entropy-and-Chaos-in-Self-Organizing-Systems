import pandas as pd
import numpy as np
from scipy.stats import entropy
import os

class LETDiagnosticEngine:
    """
    Core engine for the Lyapunov-Entropy-Topology (LET) framework.
    Calculates multi-dimensional integrity metrics from spinal kinematic datasets.
    """
    def __init__(self):
        # Academic Constants (Refer to Section 3.8 & Equation 15)
        self.LAMBDA_TARGET = 0.1245  # Physiological stability attractor
        self.W1 = 2640.0             # Weight: Dynamical Instability
        self.W2 = 617.0              # Weight: Informational Complexity
        self.W3 = 500.0              # Weight: Topological Integrity
        
        # Data Environment Setup
        self._load_demographics()
    def _load_demographics(self):
        """Loads participant metadata and cohort identifiers."""
        try:
            demo = pd.read_csv('Database Demographics.csv', sep=';', encoding='latin1')
            demo.columns = demo.columns.str.strip()
            self.hv_ids = demo[demo['Participant Type'] == 'C']['Participant Number'].astype(str).tolist()
            self.p_ids = demo[demo['Participant Type'] == 'P']['Participant Number'].astype(str).tolist()
        except FileNotFoundError:
            print("Warning: Demographics file not found. Ensure 'Database Demographics.csv' is in path.")

    def compute_dynamics(self, filename, cohort_ids):
        """
        Estimates Lyapunov Exponents and Shannon Entropy.
        Corresponds to Equations 4 and 7 in the LET framework.
        """
        df = pd.read_csv(filename, sep=';', encoding='latin1')
        valid_cols = [c for c in df.columns if any(str(idx) in str(c) for idx in cohort_ids)]
        
        lle_acc, h_acc = [], []
        for col in valid_cols:
            data = pd.to_numeric(df[col], errors='coerce').dropna().values
            if len(data) > 10:
                # LLE Estimation (Short-term divergence proxy)
                lle = np.mean(np.log(np.abs(np.diff(data)) + 1e-9)) * -0.1
                # Shannon Entropy (State occupancy probability)
                counts, _ = np.histogram(data, bins=15, density=True)
                h = entropy(counts[counts > 0])
                
                lle_acc.append(lle)
                h_acc.append(h)
                
        return np.nanmean(lle_acc), np.nanmean(h_acc)
    def compute_topological_integrity(self, filename):
        """
        Calculates the Stress Riser Ratio (T) based on translation variance.
        Directly supports Table 1 and Figure 3.
        """
        df = pd.read_csv(filename, sep=';', encoding='latin1')
        hv_cols = [c for c in df.columns if any(str(idx) in str(c) for idx in self.hv_ids)]
        p_cols = [c for c in df.columns if any(str(idx) in str(c) for idx in self.p_ids)]
        
        hv_baseline = np.nanmean([pd.to_numeric(df[c], errors='coerce').std() for c in hv_cols])
        p_variation = np.nanmean([pd.to_numeric(df[c], errors='coerce').std() for c in p_cols])
        
        return p_variation / hv_baseline  # Topological Integrity Ratio (T)

    def calculate_risk_score(self, lle, h, t_ratio):
        """
        Computes the Global Risk Score (J) using scale-parity weights.
        Refers to Equation 15: J = w1(λ - λ_target)^2 + w2(H) + w3(1/T)
        """
        term_instability = self.W1 * (lle - self.LAMBDA_TARGET)**2
        term_complexity = self.W2 * h
        term_topology = self.W3 * (1.0 / t_ratio)
        
        return term_instability + term_complexity + term_topology

# --- Main Validation Script ---
if __name__ == "__main__":
    engine = LETDiagnosticEngine()

    # Step 1: Kinematic and Dynamical Analysis
    f_lle, f_h = engine.compute_dynamics('Flexion Vert-Angle.csv', engine.p_ids)
    e_lle, e_h = engine.compute_dynamics('Extension Disc Height.csv', engine.p_ids)

    # Step 2: Topological Integrity Ratio Calculation
    t_flexion = engine.compute_topological_integrity('Flexion Translation.csv')
    t_extension = engine.compute_topological_integrity('Extension Translation.csv')

    # Step 3: Global Risk Score Generation
    j_flexion = engine.calculate_risk_score(f_lle, f_h, t_flexion)
    j_extension = engine.calculate_risk_score(e_lle, e_h, t_extension)
    print("-" * 40)
    print("LET DIAGNOSTIC INTEGRITY REPORT")
    print("-" * 40)
    print(f"Flexion Risk Score (J):     {j_flexion:.2f}")
    print(f"Extension Risk Score (J):   {j_extension:.2f}")
    print(f"Stress Riser Ratio (T_flex): {t_flexion:.3f}")
    print(f"Stress Riser Ratio (T_ext):  {t_extension:.3f}")
    print("-" * 40)
